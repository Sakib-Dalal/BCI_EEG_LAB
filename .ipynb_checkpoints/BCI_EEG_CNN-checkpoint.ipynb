{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9392b0bc-dc54-4b00-afd9-9ec27b5034f5",
   "metadata": {},
   "source": [
    "# CNN based EEG BCI prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99097982-eb8a-4be3-ac69-b48f58338bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b428705-c38c-44eb-9d61-6bb0c68cb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb63c20-c848-4e8f-b3c5-505fdd3f7ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ffe2cff-7708-4efc-9fe3-f90d8ed951db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from moabb.datasets import BNCI2014_001\n",
    "from moabb.paradigms import MotorImagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12267707-e780-4021-a4aa-7c82837b27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bci_data(subject_id=1):\n",
    "    print(f\"Downloading/Loading data for Subject {subject_id}...\")\n",
    "\n",
    "    dataset = BNCI2014_001()\n",
    "    dataset.subject_list = [subject_id]\n",
    "\n",
    "    # define paradigm\n",
    "    paradigm = MotorImagery(n_classes=2, fmin=8, fmax=32)\n",
    "\n",
    "    # get the data \n",
    "    X, y, metadata = paradigm.get_data(dataset=dataset, subjects=[subject_id])\n",
    "\n",
    "    # encode labels\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(y)\n",
    "\n",
    "    print(f\"Data Loaded: {X.shape}, Classes: {encoder.classes_}\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0b1305-a230-463b-9d58-8b78e29d8013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch CNN model\n",
    "\n",
    "class BCICNN(nn.Module):\n",
    "    def __init__(self, input_channels, base_filters=64, num_classes=4, dropout=0.3):\n",
    "        super(BCICNN, self).__init__()\n",
    "\n",
    "        # block 1\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_channels, out_channels=base_filters, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(base_filters)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # block 2\n",
    "        self.conv2 = nn.Conv1d(in_channels=base_filters, out_channels=base_filters*2, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(base_filters*2)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # block 3\n",
    "        self.conv3 = nn.Conv1d(in_channels=base_filters*2, out_channels=base_filters*4, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(base_filters*4)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # classification head\n",
    "        self.fc = nn.Linear(in_features=base_filters*4, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, channels, time)\n",
    "\n",
    "        # block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = x.squeeze(-1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03f5b962-edb9-4717-9537-5cb85d754169",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_FILTERS = 64\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89bf5df3-d1af-4209-9d7a-3271982ad49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Choosing from all possible events\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading/Loading data for Subject 1...\n",
      "Data Loaded: (576, 22, 1001), Classes: ['feet' 'left_hand' 'right_hand' 'tongue']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((576, 22, 1001), (576,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw, y_raw = get_bci_data(subject_id=1)\n",
    "\n",
    "X_raw.shape, y_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a78f29e-f4e6-451f-9025-d92b10180979",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, C, T = X_raw.shape\n",
    "scaler = StandardScaler()\n",
    "X_raw = scaler.fit_transform(X_raw.reshape(-1, C)).reshape(N, C, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8582a336-66be-4a37-af8b-bdcf4a86dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "X_tensor = torch.tensor(X_raw, dtype=torch.float32).to(DEVICE)\n",
    "y_tensor = torch.tensor(y_raw, dtype=torch.long).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd127f66-be8d-485a-b19c-4a8f4a21f150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89688a67-6bca-469f-abe9-6f9054733844",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e73baf-a1b2-4f76-97e7-6962efe3f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BCICNN(\n",
    "    input_channels=C,\n",
    "    base_filters=NUM_FILTERS,\n",
    "    num_classes=4,\n",
    "    dropout=0.3\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b290516f-58ae-4458-b596-51b8f078e776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCICNN(\n",
       "  (conv1): Conv1d(22, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (conv2): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  (bn3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (adaptive_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (fc): Linear(in_features=256, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "732f3070-0e3b-41d4-9d60-8f3ddf74e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abe2a2-da43-4e59-a891-f87fd03fdf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Loss: 0.3689\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch: {epoch+1} | Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a6f18-9e5a-42a0-8215-0a12c164f2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uv-bci-lab)",
   "language": "python",
   "name": "bci-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
